Justifying Choices we made

Using Libraries
NumPy : We are using this library in the metrics since we need access to the mathematical 
functions in numpy in order to compute the calculations necessary for applying metrics. 

SkLearn : We are using various models from the sklearn library through the use of wrappers. 
This is helpful because it allows us to make use of models that we did not program ourselves 
and use the functionality while still keeping in line with our code and being able to call our 
own functions to retrieve the values. It was also stated in the instructions that we are not 
allowed to use auto libraries but we are allowed to use libraries for models, which is what we 
have implemented.

Pandas : Pandas makes working with data a lot simpler, especially with tools like DataFrame 
letting us organize and manage data more intuitively. Our class uses Pandas to convert dataframes 
to CSV format and back which is very useful when it comes to saving and loading data.

Seaborn : We used this in order to create the graphs for the part 3 bonus. This allowed us to easily 
make graphs like a confusion matrix and a heat map that were very useful in visually displaying the 
predictions we made.

Matplot : Just as the one above, we used this for the graphical representation of the predictions, 
which was a very nice addition to our project and really helped visualize what we were computing so 
that the user can see how the different models perform.


Artifact as not an ABC
We noticed that in the description of the assignment it might be hinted at the fact that the artifact 
class should be an abstract base class (ABC), which is something that some of the TA’s also said they can 
imagine being the case, but we decided against that way of implementation. The reason for this is that we 
not only wanted to convey some concrete methods but also wanted to be able to instantiate artifacts. We 
found that to be necessary especially in the ezra requirements in the second part of the project when working 
with streamlit when it comes to saving. The instructions also explicitly state that “ Prompt the user to give 
a name and version for the pipeline and convert it into an artifact which can be saved.”, which also cannot 
be done if Artifact is an ABC since you cannot make an instance of an ABC. For this reason we chose not to make 
it an ABC even though it still has other classes inheriting from it and overriding some of the methods 
(not all- only read and save).

Edits in Pipeline and preprocess_features
In order for the classification data to be handled correctly, we needed to edit the _preprocess_features method 
in the Pipeline class as well as the preprocess_features method it is calling. Even though the shape of the input 
vector for both types of datasets was (1000, 1), for the regression dataset the shape of the output vector was correctly 
handled to be (1000, 1). However, the classification datasets were not handled correctly and the shape returning was 
(1000, 2). This couldn’t then be further processed in the split method and subsequently evaluated by the metrics correctly, 
so we implemented fixes in both.

Adding another method to the pipeline: predict
In order to extend the functionality of the deployment file to make predictions based on a new dataset, we had to 
create a new predict method in the pipeline. This is because we wanted to use a previously trained model and then 
make predictions on new data using that model without training the model on the new data. For this reason we could 
not use the already existing evaluate method or the execute method, because they did not return the right things or 
they also included a step that splits the data and trains the model. In our new predict method we only handle 
prediction with new data that is passed as an argument.

GENERAL CHOICES:
As a bonus we chose to implement a what if analysis as well as graphical representations of the predictions that 
the model makes. We chose to do this in deployment and call the different function from within the code that makes 
the predictions. This is because, despite being their own steps, both of these bonus features should appear when 
the predictions are displayed. 


HTML documentation
HTML documentation was created based on our provided docstrings in classes and methods, generated by sphinx. 
It can be found in the folder documentation, running the file FINAL PROJECT GROUP 38 DOCUMENTATION.html. 

Disclaimer for Flake 8:
There is a flake8 error: 
“./autoop/core/ml/artifact.py:41:25: ANN401 Dynamically typed expressions (typing.Any) are disallowed”
But we are not using dynamically typed expressions there. We are simply importing Any from typing and then 
using it, we are not doing typing.Any. We tried using ‘object’ instead of ‘Any’ and that worked for the style 
check but then when re-running the tests for Part I of the assignment, the tests would fail saying we cannot 
import ‘object’  from typing. So we decided to keep it as Any, since we are using it correctly, like is also 
done in other parts of the codebase that we did not code, and put this disclaimer here. 
